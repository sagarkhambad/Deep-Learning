{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Call_Backs.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AQDRNrY2NCXf"
      },
      "source": [
        "<pre>\n",
        "1. Download the data from <a href='https://drive.google.com/file/d/15dCNcmKskcFVjs7R0ElQkR61Ex53uJpM/view?usp=sharing'>here</a>\n",
        "\n",
        "2. Code the model to classify data like below image\n",
        "\n",
        "<img src='https://i.imgur.com/33ptOFy.png'>\n",
        "\n",
        "3. Write your own callback function, that has to print the micro F1 score and AUC score after each epoch.\n",
        "\n",
        "4. Save your model at every epoch if your validation accuracy is improved from previous epoch. \n",
        "\n",
        "5. you have to decay learning based on below conditions \n",
        "        Cond1. If your validation accuracy at that epoch is less than previous epoch accuracy, you have to decrese the\n",
        "               learning rate by 10%. \n",
        "        Cond2. For every 3rd epoch, decay your learning rate by 5%.\n",
        "        \n",
        "6. If you are getting any NaN values(either weigths or loss) while training, you have to terminate your training. \n",
        "\n",
        "7. You have to stop the training if your validation accuracy is not increased in last 2 epochs.\n",
        "\n",
        "8. Use tensorboard for every model and analyse your gradients. (you need to upload the screenshots for each model for evaluation)\n",
        "\n",
        "9. use cross entropy as loss function\n",
        "\n",
        "10. Try the architecture params as given below. \n",
        "</pre>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w41Y3TFENCXk"
      },
      "source": [
        "<pre>\n",
        "<b>Model-1</b>\n",
        "<pre>\n",
        "1. Use tanh as an activation for every layer except output layer.\n",
        "2. use SGD with momentum as optimizer.\n",
        "3. use RandomUniform(0,1) as initilizer.\n",
        "3. Analyze your output and training process. \n",
        "</pre>\n",
        "</pre>\n",
        "<pre>\n",
        "<b>Model-2</b>\n",
        "<pre>\n",
        "1. Use relu as an activation for every layer except output layer.\n",
        "2. use SGD with momentum as optimizer.\n",
        "3. use RandomUniform(0,1) as initilizer.\n",
        "3. Analyze your output and training process. \n",
        "</pre>\n",
        "</pre>\n",
        "<pre>\n",
        "<b>Model-3</b>\n",
        "<pre>\n",
        "1. Use relu as an activation for every layer except output layer.\n",
        "2. use SGD with momentum as optimizer.\n",
        "3. use he_uniform() as initilizer.\n",
        "3. Analyze your output and training process. \n",
        "</pre>\n",
        "</pre>\n",
        "<pre>\n",
        "<b>Model-4</b>\n",
        "<pre>\n",
        "1. Try with any values to get better accuracy/f1 score.  \n",
        "</pre>\n",
        "</pre>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rf7CIXndkTSy",
        "outputId": "b03d85fa-fb3c-4869-f75d-0770f1686775"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "edK7eg4Mj6PU"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import pickle\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score,roc_auc_score\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.layers import Dense,Input,Activation,BatchNormalization, Dropout\n",
        "from tensorflow.keras.initializers import RandomUniform\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q-AvoNdlkHM_"
      },
      "source": [
        "data=pd.read_csv(\"/content/drive/MyDrive/AppliedMachineLearning/DeepLearning/data.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fFxkVhWwlsbN",
        "outputId": "44164f69-ad0d-4204-f86f-33566ee47d67"
      },
      "source": [
        "data.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(20000, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dSvvnifOl3j_",
        "outputId": "e00a5fea-c27b-405d-8fc0-41c277afa447"
      },
      "source": [
        "data.columns"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['f1', 'f2', 'label'], dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WvUwvXb6l1Co"
      },
      "source": [
        "X=data[[\"f1\",\"f2\"]].values\n",
        "y=data[\"label\"].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q_9newAxk0-u"
      },
      "source": [
        "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Emw_01NAmGSo",
        "outputId": "a3f0e2de-6c4e-48b8-f9d9-98ff36032351"
      },
      "source": [
        "print(X_train.shape)\n",
        "print(X_test.shape)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(16000, 2)\n",
            "(4000, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IuLMbrM5tDck",
        "outputId": "7bfae00f-0aa2-4c7b-f21c-5ce119ad03a8"
      },
      "source": [
        "print(y_train.shape)\n",
        "print(y_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(16000,)\n",
            "(4000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F-SMkjt45nGr"
      },
      "source": [
        "batch_size = 128 "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZbevrOskezaI"
      },
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.callbacks import LearningRateScheduler\n",
        "\n",
        "class Metrics(tf.keras.callbacks.Callback):\n",
        "  def __init__(self,validation_data):\n",
        "    super().__init__()\n",
        "    self.x_val=validation_data[0]\n",
        "    self.y_val=validation_data[1]\n",
        "\n",
        "  def on_train_begin(self, logs={}):\n",
        "      self.history={\"loss\":[],\"acc\":[],\"val_loss\":[],\"val_acc\":[],\"val_f1\":[],\"val_auc\":[]}\n",
        "\n",
        "  def on_epoch_end(self, epoch, logs):\n",
        "      y_val_pred_proba =np.asanyarray(self.model.predict(self.x_val))\n",
        "      y_val_pred=[1 if val>0.5 else 0 for val in list(y_val_pred_proba)]\n",
        "      val_f1 = round(f1_score(self.y_val,y_val_pred,average='micro'), 4)\n",
        "      val_auc = round(roc_auc_score(self.y_val,y_val_pred_proba), 4)\n",
        "      self.history[\"val_f1\"].append(val_f1)\n",
        "      self.history[\"val_auc\"].append(val_auc)\n",
        "      self.history['loss'].append(logs.get('loss'))\n",
        "      self.history['acc'].append(logs.get('accuracy'))\n",
        "      self.history['val_loss'].append(logs.get('val_loss'))\n",
        "      self.history['val_acc'].append(logs.get('val_accuracy'))\n",
        "\n",
        "      loss = logs.get('loss')\n",
        "      if loss is not None:\n",
        "          if np.isnan(loss) or np.isinf(loss):\n",
        "              print(\"Invalid loss and terminated at epoch {}\".format(epoch))\n",
        "              self.model.stop_training = True\n",
        "\n",
        "      if epoch>0 and (logs.get(\"val_accuracy\")>self.history[\"val_acc\"][epoch-1]):\n",
        "        self.model.save(\"/content/drive/MyDrive/AppliedMachineLearning/DeepLearning/model_save/epoch-{}_val_acc-{}.pkl\".format(epoch,\n",
        "                                                                                                                               np.round(logs.get(\"val_accuracy\"),2)))\n",
        "        \n",
        "\n",
        "      if epoch>1 and (logs.get(\"val_accuracy\")-self.history[\"val_acc\"][epoch-2])<0.001:\n",
        "        self.model.stop_training = True\n",
        "\n",
        "      print(\"- val_f1: {} - val_auc: {}\".format(val_f1,val_auc))\n",
        "      return\n",
        "\n",
        "\n",
        "def changeLearningRate(epoch):\n",
        "  global learningrate\n",
        "  if epoch>1 and metrics.history[\"val_acc\"][epoch-1]<metrics.history[\"val_acc\"][epoch-2] and (epoch%3)!=0:\n",
        "    learningrate = learningrate*(1-0.1)\n",
        "  if (epoch+1)%3==0:\n",
        "    learningrate = learningrate*(1-0.05)    \n",
        "  return learningrate\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WRsWuPxou8Mb"
      },
      "source": [
        "%load_ext tensorboard"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UVS8KmO152iU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45ec5068-f8b0-4198-c54e-7ca662db18e5"
      },
      "source": [
        "#Input layer\n",
        "input_layer = Input(shape=(2,))\n",
        "#Dense hidden layer\n",
        "layer1 = Dense(512,activation='tanh',kernel_initializer=tf.keras.initializers.RandomUniform(minval=0,maxval=1,seed=30))(input_layer)\n",
        "layer2 = Dense(256,activation='tanh',kernel_initializer=tf.keras.initializers.RandomUniform(minval=0,maxval=1,seed=30))(layer1)\n",
        "layer3 = Dense(128,activation='tanh',kernel_initializer=tf.keras.initializers.RandomUniform(minval=0,maxval=1,seed=30))(layer2)\n",
        "layer4 = Dense(64,activation='tanh',kernel_initializer=tf.keras.initializers.RandomUniform(minval=0,maxval=1,seed=30))(layer3)\n",
        "layer5 = Dense(32,activation='tanh',kernel_initializer=tf.keras.initializers.RandomUniform(minval=0,maxval=1,seed=30))(layer4)\n",
        "#output layer\n",
        "output = Dense(1,activation='sigmoid',kernel_initializer=tf.keras.initializers.RandomUniform(minval=0,maxval=1,seed=30))(layer5)\n",
        "#Creating a model\n",
        "model = Model(inputs=input_layer,outputs=output)\n",
        "\n",
        "learningrate=0.1\n",
        "metrics=Metrics(validation_data=(X_test,y_test))\n",
        "lrschedule = LearningRateScheduler(changeLearningRate,verbose=1)\n",
        "\n",
        "\n",
        "model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=0.1, momentum=0.9), loss='binary_crossentropy',metrics=['accuracy'])\n",
        "import datetime\n",
        "log_dir=\"/content/drive/MyDrive/AppliedMachineLearning/DeepLearning/logs/fit\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir,histogram_freq=1, write_graph=True,write_grads=True)\n",
        "model.fit(X_train, y_train,validation_data=(X_test,y_test),epochs=30,batch_size=128,callbacks=[metrics,lrschedule,tensorboard_callback])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:`write_grads` will be ignored in TensorFlow 2.0 for the `TensorBoard` Callback.\n",
            "Epoch 1/30\n",
            "\n",
            "Epoch 00001: LearningRateScheduler reducing learning rate to 0.1.\n",
            "  3/125 [..............................] - ETA: 5s - loss: 6.0336 - accuracy: 0.5052 WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0059s vs `on_train_batch_end` time: 0.0122s). Check your callbacks.\n",
            "125/125 [==============================] - 2s 9ms/step - loss: 1.1174 - accuracy: 0.4958 - val_loss: 0.7152 - val_accuracy: 0.5135\n",
            "- val_f1: 0.5135 - val_auc: 0.5135\n",
            "Epoch 2/30\n",
            "\n",
            "Epoch 00002: LearningRateScheduler reducing learning rate to 0.1.\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.7229 - accuracy: 0.5008 - val_loss: 0.6953 - val_accuracy: 0.5135\n",
            "- val_f1: 0.5135 - val_auc: 0.5135\n",
            "Epoch 3/30\n",
            "\n",
            "Epoch 00003: LearningRateScheduler reducing learning rate to 0.095.\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.7063 - accuracy: 0.4957 - val_loss: 0.7372 - val_accuracy: 0.4865\n",
            "- val_f1: 0.4865 - val_auc: 0.4865\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fd299ea62d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zPs-uH6ctg6S"
      },
      "source": [
        "%tensorboard --logdir /content/drive/MyDrive/AppliedMachineLearning/DeepLearning/logs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q18E15-9otP8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "440926d4-b1e3-4691-9c9f-23bf11e8e917"
      },
      "source": [
        "#Input layer\n",
        "input_layer = Input(shape=(2,))\n",
        "#Dense hidden layer\n",
        "layer1 = Dense(512,activation='relu',kernel_initializer=tf.keras.initializers.RandomUniform(minval=0,maxval=1,seed=30))(input_layer)\n",
        "layer2 = Dense(256,activation='relu',kernel_initializer=tf.keras.initializers.RandomUniform(minval=0,maxval=1,seed=30))(layer1)\n",
        "layer3 = Dense(128,activation='relu',kernel_initializer=tf.keras.initializers.RandomUniform(minval=0,maxval=1,seed=30))(layer2)\n",
        "layer4 = Dense(64,activation='relu',kernel_initializer=tf.keras.initializers.RandomUniform(minval=0,maxval=1,seed=30))(layer3)\n",
        "layer5 = Dense(32,activation='relu',kernel_initializer=tf.keras.initializers.RandomUniform(minval=0,maxval=1,seed=30))(layer4)\n",
        "#output layer\n",
        "output = Dense(1,activation='sigmoid',kernel_initializer=tf.keras.initializers.RandomUniform(minval=0,maxval=1,seed=30))(layer5)\n",
        "#Creating a model\n",
        "model_1 = Model(inputs=input_layer,outputs=output)\n",
        "\n",
        "learningrate=0.1\n",
        "metrics=Metrics(validation_data=(X_test,y_test))\n",
        "lrschedule = LearningRateScheduler(changeLearningRate,verbose=1)\n",
        "\n",
        "model_1.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=0.1, momentum=0.9), loss='binary_crossentropy',metrics=['accuracy'])\n",
        "import datetime\n",
        "log_dir=\"/content/drive/MyDrive/AppliedMachineLearning/DeepLearning/logs_1/fit\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir,histogram_freq=1, write_graph=True,write_grads=True)\n",
        "model_1.fit(X_train, y_train,validation_data=(X_test,y_test),epochs=30,batch_size=128,callbacks=[metrics,lrschedule,tensorboard_callback])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:`write_grads` will be ignored in TensorFlow 2.0 for the `TensorBoard` Callback.\n",
            "Epoch 1/30\n",
            "\n",
            "Epoch 00001: LearningRateScheduler reducing learning rate to 0.1.\n",
            "  3/125 [..............................] - ETA: 4s - loss: 35646816.0000 - accuracy: 0.5052  WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0081s vs `on_train_batch_end` time: 0.0104s). Check your callbacks.\n",
            "125/125 [==============================] - 2s 9ms/step - loss: 855523.5625 - accuracy: 0.4964 - val_loss: 0.6933 - val_accuracy: 0.4913\n",
            "- val_f1: 0.4912 - val_auc: 0.5\n",
            "Epoch 2/30\n",
            "\n",
            "Epoch 00002: LearningRateScheduler reducing learning rate to 0.1.\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.6938 - accuracy: 0.4991 - val_loss: 0.6940 - val_accuracy: 0.4913\n",
            "- val_f1: 0.4912 - val_auc: 0.5\n",
            "Epoch 3/30\n",
            "\n",
            "Epoch 00003: LearningRateScheduler reducing learning rate to 0.095.\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.6935 - accuracy: 0.4982 - val_loss: 0.6930 - val_accuracy: 0.5088\n",
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/AppliedMachineLearning/DeepLearning/model_save/epoch-2_val_acc-0.51.pkl/assets\n",
            "- val_f1: 0.5088 - val_auc: 0.5\n",
            "Epoch 4/30\n",
            "\n",
            "Epoch 00004: LearningRateScheduler reducing learning rate to 0.095.\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.6936 - accuracy: 0.4977 - val_loss: 0.6931 - val_accuracy: 0.5088\n",
            "- val_f1: 0.5088 - val_auc: 0.5\n",
            "Epoch 5/30\n",
            "\n",
            "Epoch 00005: LearningRateScheduler reducing learning rate to 0.095.\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.6939 - accuracy: 0.5008 - val_loss: 0.6931 - val_accuracy: 0.5088\n",
            "- val_f1: 0.5088 - val_auc: 0.5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f389d74d310>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bnxg11c8x6Hh"
      },
      "source": [
        "%tensorboard --logdir /content/drive/MyDrive/AppliedMachineLearning/DeepLearning/logs_1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nidsyrd9Y-pw",
        "outputId": "0c50eabc-c83e-4586-8e9d-65a4c74b6d78"
      },
      "source": [
        "#Input layer\n",
        "input_layer = Input(shape=(2,))\n",
        "#Dense hidden layer\n",
        "layer1 = Dense(512,activation='relu',kernel_initializer=tf.keras.initializers.he_uniform())(input_layer)\n",
        "layer2 = Dense(256,activation='relu',kernel_initializer=tf.keras.initializers.he_uniform())(layer1)\n",
        "layer3 = Dense(128,activation='relu',kernel_initializer=tf.keras.initializers.he_uniform())(layer2)\n",
        "layer4 = Dense(64,activation='relu',kernel_initializer=tf.keras.initializers.he_uniform())(layer3)\n",
        "layer5 = Dense(32,activation='relu',kernel_initializer=tf.keras.initializers.he_uniform())(layer4)\n",
        "#output layer\n",
        "output = Dense(1,activation='sigmoid',kernel_initializer=tf.keras.initializers.he_uniform())(layer5)\n",
        "#Creating a model\n",
        "model = Model(inputs=input_layer,outputs=output)\n",
        "\n",
        "learningrate=0.1\n",
        "metrics=Metrics(validation_data=(X_test,y_test))\n",
        "lrschedule = LearningRateScheduler(changeLearningRate,verbose=1)\n",
        "\n",
        "model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=0.1, momentum=0.9), loss='binary_crossentropy',metrics=['accuracy'])\n",
        "\n",
        "import datetime\n",
        "log_dir=\"/content/drive/MyDrive/AppliedMachineLearning/DeepLearning/logs_2/fit\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir,histogram_freq=1, write_graph=True,write_grads=True)\n",
        "model.fit(X_train, y_train,validation_data=(X_test,y_test),epochs=30,batch_size=128,callbacks=[metrics,lrschedule,tensorboard_callback])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:`write_grads` will be ignored in TensorFlow 2.0 for the `TensorBoard` Callback.\n",
            "Epoch 1/30\n",
            "\n",
            "Epoch 00001: LearningRateScheduler reducing learning rate to 0.1.\n",
            "  3/125 [..............................] - ETA: 5s - loss: 0.8267 - accuracy: 0.4922 WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0065s vs `on_train_batch_end` time: 0.0126s). Check your callbacks.\n",
            "125/125 [==============================] - 2s 8ms/step - loss: 0.6674 - accuracy: 0.5860 - val_loss: 0.6365 - val_accuracy: 0.6300\n",
            "- val_f1: 0.63 - val_auc: 0.6865\n",
            "Epoch 2/30\n",
            "\n",
            "Epoch 00002: LearningRateScheduler reducing learning rate to 0.1.\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.6363 - accuracy: 0.6403 - val_loss: 0.7064 - val_accuracy: 0.5470\n",
            "- val_f1: 0.547 - val_auc: 0.703\n",
            "Epoch 3/30\n",
            "\n",
            "Epoch 00003: LearningRateScheduler reducing learning rate to 0.0855.\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.6244 - accuracy: 0.6483 - val_loss: 0.6112 - val_accuracy: 0.6605\n",
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/AppliedMachineLearning/DeepLearning/model_save/epoch-2_val_acc-0.66.pkl/assets\n",
            "- val_f1: 0.6605 - val_auc: 0.7346\n",
            "Epoch 4/30\n",
            "\n",
            "Epoch 00004: LearningRateScheduler reducing learning rate to 0.0855.\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.6159 - accuracy: 0.6617 - val_loss: 0.6219 - val_accuracy: 0.6497\n",
            "- val_f1: 0.6498 - val_auc: 0.7344\n",
            "Epoch 5/30\n",
            "\n",
            "Epoch 00005: LearningRateScheduler reducing learning rate to 0.07695.\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.6273 - accuracy: 0.6446 - val_loss: 0.6126 - val_accuracy: 0.6622\n",
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/AppliedMachineLearning/DeepLearning/model_save/epoch-4_val_acc-0.66.pkl/assets\n",
            "- val_f1: 0.6622 - val_auc: 0.7297\n",
            "Epoch 6/30\n",
            "\n",
            "Epoch 00006: LearningRateScheduler reducing learning rate to 0.0731025.\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.6166 - accuracy: 0.6621 - val_loss: 0.6250 - val_accuracy: 0.6580\n",
            "- val_f1: 0.658 - val_auc: 0.736\n",
            "Epoch 7/30\n",
            "\n",
            "Epoch 00007: LearningRateScheduler reducing learning rate to 0.0731025.\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.6098 - accuracy: 0.6643 - val_loss: 0.6174 - val_accuracy: 0.6480\n",
            "- val_f1: 0.648 - val_auc: 0.722\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fbac9a0f750>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vQCVRWgi1IiD"
      },
      "source": [
        "%tensorboard --logdir /content/drive/MyDrive/AppliedMachineLearning/DeepLearning/logs_2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CTva8XeMZlt0",
        "outputId": "12fa4e95-300d-471b-da2f-a015ae1fa5db"
      },
      "source": [
        "#Input layer\n",
        "input_layer = Input(shape=(2,))\n",
        "#Dense hidden layer\n",
        "layer1 = Dense(512,activation='relu',kernel_initializer=tf.keras.initializers.he_uniform())(input_layer)\n",
        "layer2 = Dense(256,activation='relu',kernel_initializer=tf.keras.initializers.he_uniform())(layer1)\n",
        "layer3 = Dense(128,activation='relu',kernel_initializer=tf.keras.initializers.he_uniform())(layer2)\n",
        "layer4 = Dense(64,activation='relu',kernel_initializer=tf.keras.initializers.he_uniform())(layer3)\n",
        "layer5 = Dense(32,activation='relu',kernel_initializer=tf.keras.initializers.he_uniform())(layer4)\n",
        "#output layer\n",
        "output = Dense(1,activation='sigmoid',kernel_initializer=tf.keras.initializers.he_uniform())(layer5)\n",
        "#Creating a model\n",
        "model = Model(inputs=input_layer,outputs=output)\n",
        "\n",
        "learningrate=0.1\n",
        "metrics=Metrics(validation_data=(X_test,y_test))\n",
        "lrschedule = LearningRateScheduler(changeLearningRate,verbose=1)\n",
        "\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.1), loss='binary_crossentropy',metrics=['accuracy'])\n",
        "\n",
        "import datetime\n",
        "log_dir=\"/content/drive/MyDrive/AppliedMachineLearning/DeepLearning/logs_3/fit\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir,histogram_freq=1, write_graph=True,write_grads=True)\n",
        "model.fit(X_train, y_train,validation_data=(X_test,y_test),epochs=30,batch_size=128,callbacks=[metrics,lrschedule,tensorboard_callback])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:`write_grads` will be ignored in TensorFlow 2.0 for the `TensorBoard` Callback.\n",
            "Epoch 1/30\n",
            "\n",
            "Epoch 00001: LearningRateScheduler reducing learning rate to 0.1.\n",
            "  3/125 [..............................] - ETA: 7s - loss: 286.5075 - accuracy: 0.5156WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0068s vs `on_train_batch_end` time: 0.0183s). Check your callbacks.\n",
            "125/125 [==============================] - 2s 10ms/step - loss: 7.7304 - accuracy: 0.6416 - val_loss: 0.6154 - val_accuracy: 0.6530\n",
            "- val_f1: 0.653 - val_auc: 0.7322\n",
            "Epoch 2/30\n",
            "\n",
            "Epoch 00002: LearningRateScheduler reducing learning rate to 0.1.\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.6098 - accuracy: 0.6646 - val_loss: 0.6075 - val_accuracy: 0.6697\n",
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/AppliedMachineLearning/DeepLearning/model_save/epoch-1_val_acc-0.67.pkl/assets\n",
            "- val_f1: 0.6698 - val_auc: 0.73\n",
            "Epoch 3/30\n",
            "\n",
            "Epoch 00003: LearningRateScheduler reducing learning rate to 0.095.\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.6093 - accuracy: 0.6630 - val_loss: 0.6103 - val_accuracy: 0.6683\n",
            "- val_f1: 0.6682 - val_auc: 0.7294\n",
            "Epoch 4/30\n",
            "\n",
            "Epoch 00004: LearningRateScheduler reducing learning rate to 0.095.\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.6065 - accuracy: 0.6662 - val_loss: 0.6182 - val_accuracy: 0.6555\n",
            "- val_f1: 0.6555 - val_auc: 0.7337\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f1e96bf5790>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FSlnYlq_fKFE"
      },
      "source": [
        "%tensorboard --logdir /content/drive/MyDrive/AppliedMachineLearning/DeepLearning/logs_3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-9vW4KWs2kVF"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}